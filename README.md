# Hidden Markov Models
Implementation solutions to two problems associated with HMMs

The Viterbi algorithm is used for supervised tasks and the Forward-Backward algorithm is employed for semi-supervised, and unsupervised tasks.

A hidden Markov model (HMM) allows us to talk about both observed events (e.g. words) and hidden events (e.g. part-of-speech tags). An HMM is specified by the following components:

![image](https://user-images.githubusercontent.com/24508376/219600466-3be87292-2a43-4ccb-9df7-a873e32c9d8f.png)

Where ğ’‚ğ’Šğ’‹ = ğ‘·ğ’“(ğ’’ğ’•+ğŸ = ğ‘ºğ’‹|ğ’’ğ’• = ğ‘ºğ’Š) = (ğ’’ğ’•+ğŸ = ğ’•ğ’‚ğ’ˆğ’‹|ğ’’ğ’• = ğ’•ğ’‚ğ’ˆğ’Š), and ğ’ƒğ’‹ğ’Œ = ğ‘·ğ’“(ğ‘¶ğ’• = ğ’Œ|ğ’’ğ’• = ğ‘ºğ’‹) = ğ‘·ğ’“(ğ‘¶ğ’• = ğ’˜ğ’ğ’“ğ’…ğ’Œ|ğ’’ğ’• = ğ’•ğ’‚ğ’ˆğ’‹).

# The Viterbi Algorithm (supervised task)
For any model, such as an HMM, that contains hidden variables, the task of finding which sequence of variables is the most likely tag sequence given the sequence of observations (words), is called the decoding task. The task of the decoder is to find the best hidden variable sequence (ğ‘1ğ‘2ğ‘3 â€¦ ğ‘ğ‘›). The most common decoding algorithms for HMMs is the Viterbi algorithm. This algorithm is a kind of dynamic programming.

Each cell ğ’—ğ’•( ğ’‹), represents the probability that the HMM is in state ğ’‹ after seeing the first ğ’• observations and passing through the most probable state sequence ğ‘1 â€¦ ğ‘ğ‘¡âˆ’1. The value of each cell ğ’—ğ’•( ğ’‹) is computed by recursively taking the most probable path. Like other dynamic programming algorithms, Viterbi fills each cell recursively. The Viterbi probability is computed by taking the most probable of the extensions of the paths that lead to the current cell, provided the Viterbi probability had already been calculated in every state at time ğ‘¡ âˆ’ 1. For a given state ğ’’ğ’‹ at time t, the Viterbi probability ğ’—ğ’•( ğ’‹) is computed in log space as:

            ğ‘
ğ‘£ğ‘¡ (ğ‘—) â†   ğ‘šğ‘ğ‘¥ ( ğ‘£ğ‘¡âˆ’1(ğ‘–) + ln (ğ‘ğ‘–ğ‘— ) + l n (ğ‘ğ‘—(ğ‘œğ‘¡ )))
          ğ‘– = 1
    
    
Where ğ‘£ğ‘¡âˆ’1(ğ‘–) is the previous Viterbi path probability from the previous time step, ğ‘ğ‘–ğ‘— is the transition probability from previous state ğ‘ğ‘– to the current state ğ‘ğ‘—, and ğ‘ğ‘—(ğ‘œğ‘¡ ) is the emission probability of the observation symbol ğ‘œğ‘¡ given the current state ğ‘—. Pseudocode for the Viterbi algorithm is given in the following.

Function VITERBI (observations of len T, state-graph of len N) returns best-path
create a path probability matrix ğ‘£ğ‘–ğ‘¡ğ‘’ğ‘Ÿğ‘ğ‘–[ğ‘, ğ‘‡]
for each state s from 1 to N do // Initialization step
  ğ‘£ğ‘–ğ‘¡ğ‘’ğ‘Ÿğ‘ğ‘–[ğ‘ , 1] â† ln (ğœ‹ğ‘  ) + ln (ğ‘ğ‘  (ğ‘œ1))
  ğ‘ğ‘ğ‘ğ‘˜ğ‘ğ‘œğ‘–ğ‘›ğ‘¡ğ‘’ğ‘Ÿ[ğ‘ , 1] â† 0
for each time step t from 2 to T do // recursion step
  for each state s from 1 to N do
                                   ğ‘
    ğ‘£ğ‘–ğ‘¡ğ‘’ğ‘Ÿğ‘ğ‘–[ğ‘ , ğ‘¡] â† l n(ğ‘ğ‘  (ğ‘œğ‘¡ )) + ğ‘šğ‘ğ‘¥ ( ğ‘£ğ‘–ğ‘¡ğ‘’ğ‘Ÿğ‘ğ‘–[ğ‘ â€², ğ‘¡ âˆ’ 1] + ln (ğ‘ğ‘ â€²,ğ‘  ) )
                                ğ‘ â€² = 1
   
                         ğ‘
    ğ‘ğ‘ğ‘ğ‘˜ğ‘ğ‘œğ‘–ğ‘›ğ‘¡ğ‘’ğ‘Ÿ[ğ‘ , ğ‘¡] â† ğ‘ğ‘Ÿğ‘”ğ‘šğ‘ğ‘¥ ğ‘£ğ‘–ğ‘¡ğ‘’ğ‘Ÿğ‘ğ‘–[ğ‘ â€², ğ‘¡ âˆ’ 1] + ln (ğ‘ğ‘ â€²,ğ‘  ))
                      ğ‘ â€² = 1

                    ğ‘
  ğ‘ğ‘’ğ‘ ğ‘¡ğ‘ğ‘ğ‘¡â„ğ‘ğ‘œğ‘–ğ‘›ğ‘¡ğ‘’ğ‘Ÿ â†  ğ‘ğ‘Ÿğ‘”ğ‘šğ‘ğ‘¥ ğ‘£ğ‘–ğ‘¡ğ‘’ğ‘Ÿğ‘ğ‘–[ğ‘ , ğ‘‡] // termination step
                  ğ‘  = 1
ğ‘ğ‘’ğ‘ ğ‘¡ğ‘ğ‘ğ‘¡â„ â† ğ‘¡â„ğ‘’ ğ‘ğ‘ğ‘¡â„ ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡ğ‘–ğ‘›ğ‘” ğ‘ğ‘¡ ğ‘ ğ‘¡ğ‘ğ‘¡ğ‘’ ğ‘ğ‘’ğ‘ ğ‘¡ğ‘ğ‘ğ‘¡â„ğ‘œğ‘–ğ‘›ğ‘¡ğ‘’ğ‘Ÿ, ğ‘¡â„ğ‘’ ğ‘“ğ‘œğ‘™ğ‘™ğ‘œğ‘¤ğ‘  ğ‘ğ‘ğ‘ğ‘˜ğ‘ğ‘œğ‘–ğ‘›ğ‘¡ğ‘’ğ‘Ÿ[ ]ğ‘¡ğ‘œ ğ‘ ğ‘¡ğ‘ğ‘¡ğ‘’ğ‘  ğ‘ğ‘ğ‘ğ‘˜ ğ‘–ğ‘› ğ‘¡ğ‘–ğ‘šğ‘’

return ğ‘ğ‘’ğ‘ ğ‘¡ğ‘ğ‘ğ‘¡â„

# The Forward-Backward Algorithm (semi-supervised task)
This algorithm learns the parameters of an HMM, which are, the transition probability matrix A, and the emission probability matrix B in a semi-supervised manner. In fact, the input to such a learning algorithm would be an unlabeled sequence of observations O and a vocabulary of potential hidden states Q.

The standard algorithm for HMM training is the forward-backward, or Baum-Welch algorithm, a special case of the Expectation-Maximization or EM algorithm. The algorithm trains both the transition probabilities A and the emission probabilities B of the HMM. EM is an iterative algorithm, computing an initial estimate for the probabilities, then using those estimates to computing a better estimate, and so on, iteratively improving the probabilities that it learns. The Baum-Welch algorithm solves this problem by iteratively estimating the counts. The Baum-Welch algorithm starts with an estimate for the transition and observation probabilities and then uses these estimated probabilities to derive better and better probabilities.



To understand the algorithm, we need to define the forward and backward probabilities. The forward algorithm is a kind of dynamic programming algorithm, that is, an algorithm that uses a table to store intermediate values as it builds up the probability of the observation sequence. The forward algorithm computes the observation probability by summing over the probabilities of all possible hidden state paths that could generate the observation sequence.
Each cell of the forward algorithm at ğœ¶ğ’•(ğ’‹) represents the probability of being in state ğ’‹ after seeing the first ğ’• observations. The value of each cell at ğœ¶ğ’•(ğ’‹) is computed by summing over the probabilities of every path that could lead to this cell. Formally, each cell expresses the following probability:

ğ›¼ğ‘¡ (ğ‘—) = ğ‘ƒ(ğ‘œ1, ğ‘œ2, â€¦ ğ‘œğ‘¡ . , ğ‘ğ‘¡ = ğ‘—)

Here, ğ’’ğ’• = ğ’‹ means â€œthe ğ’•ğ’•ğ’‰ state in the sequence of states is state ğ’‹â€. This probability at ğœ¶ğ’•(ğ’‹) is computed by summing over the extensions of all the paths that lead to the current cell. For a given state ğ’’ğ’‹ at time t, the value at ğœ¶ğ’•(ğ’‹) is computed as
         ğ‘
ğ›¼ğ‘¡ (ğ‘—) = Î£ ğ›¼ğ‘¡âˆ’1(ğ‘–)ğ‘ğ‘–ğ‘—ğ‘ğ‘—(ğ‘œğ‘¡)
        ğ‘–=1
Where ğ›¼ğ‘¡âˆ’1(ğ‘—) is the previous forward path probability from the previous time step. The pseudocode for the forward algorithm is given in the following.

Function ForwardAlg1 (observations of len T, state-graph of len N) returns forward-prob
create a probability matrix ğ‘“ğ‘œğ‘Ÿğ‘¤ğ‘ğ‘Ÿğ‘‘[ğ‘, ğ‘‡]
for each state s from 1 to N do // Initialization step
  ğ‘“ğ‘œğ‘Ÿğ‘¤ğ‘ğ‘Ÿğ‘‘[ğ‘ , 1] â† ğœ‹ğ‘  âˆ— ğ‘ğ‘  (ğ‘œ1)
for each time step t from 2 to T do // recursion step
  for each state s from 1 to N do
                  ğ‘
  ğ‘“ğ‘œğ‘Ÿğ‘¤ğ‘ğ‘Ÿğ‘‘[ğ‘ , ğ‘¡] â† Î£ ğ‘“ğ‘œğ‘Ÿğ‘¤ğ‘ğ‘Ÿğ‘‘[ğ‘ â€², ğ‘¡ âˆ’ 1]
                ğ‘ â€²=1
return ğ‘“ğ‘œğ‘Ÿğ‘¤ğ‘ğ‘Ÿğ‘‘


There are some implementational issues both for the Forward algorithm and the Backward algorithm described later. The most severe practical problem is that multiplying many probabilities always yields very small numbers that will give underflow errors on any computer. For this reason, the Forward algorithm has been presented by the ForwardAlg2 done in log space, which will make the numbers stay reasonable.

Function ForwardAlg2 (observations of len T, state-graph of len N) returns forward-prob
create a probability matrix ğ‘“ğ‘œğ‘Ÿğ‘¤ğ‘ğ‘Ÿğ‘‘[ğ‘, ğ‘‡]
for each state s from 1 to N do // Initialization step
  ğ‘“ğ‘œğ‘Ÿğ‘¤ğ‘ğ‘Ÿğ‘‘[ğ‘ , 1] â† ln ( ğœ‹ğ‘  ) + ln (ğ‘ğ‘  (ğ‘œ1))
for each time step t from 2 to T do // recursion step
  for each state s from 1 to N do
    ğ‘¡ğ‘šğ‘ = ğ‘“ğ‘œğ‘Ÿğ‘¤ğ‘ğ‘Ÿğ‘‘[1, ğ‘¡ âˆ’ 1] + ln(ğ‘1ğ‘  ) + ğ‘™ğ‘›(ğ‘ğ‘  (ğ‘œğ‘¡ ))
    for each state ğ‘ â€² from 2 to N
      ğ‘¡ğ‘šğ‘1 = ğ‘“ğ‘œğ‘Ÿğ‘¤ğ‘ğ‘Ÿğ‘‘[ğ‘ â€², ğ‘¡ âˆ’ 1] + ln(ğ‘ğ‘ â€²ğ‘  ) + ğ‘™ğ‘›(ğ‘ğ‘  (ğ‘œğ‘¡ ))
               {tmp + ln (1 + exp (ğ‘¡ğ‘šğ‘1 âˆ’ ğ‘¡ğ‘šğ‘))) ğ‘–ğ‘“ ğ‘¡ğ‘šğ‘1 â‰¤ ğ‘¡ğ‘šğ‘
        ğ‘¡ğ‘šğ‘ â† {
               {tmp1 + ln (1 + exp (ğ‘¡ğ‘šğ‘ âˆ’ ğ‘¡ğ‘šğ‘1))) ğ‘œ, ğ‘¤.
      ğ‘“ğ‘œğ‘Ÿğ‘¤ğ‘ğ‘Ÿğ‘‘[ğ‘ , ğ‘¡] = ğ‘¡ğ‘šğ‘
return ğ‘“ğ‘œğ‘Ÿğ‘¤ğ‘ğ‘Ÿğ‘‘


The backward probability ğœ· is the probability of seeing the observations from time ğ’• + ğŸ to the end, given in state ğ‘– at time ğ‘¡: ğœ·ğ’•(ğ’Š) = ğ‘·(ğ’ğ’•+ğŸ, ğ’ğ’•+ğŸ, â€¦ , ğ’ğ‘»|ğ’’ğ’• = ğ’Š).


